{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom wordcloud import WordCloud",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Load the dataset\ndata_path = r\"C:\\Users\\subra\\Desktop\\Projects\\New Projects\\Fake-News-Detection\\data\\data.csv\"\ndf = pd.read_csv(data_path)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Display basic information about the dataset\nprint(\"First five rows of the dataset:\")\nprint(df.head())\n\nprint(\"\\nSummary statistics of the dataset:\")\nprint(df.describe())\n\nprint(\"\\nDataset information:\")\nprint(df.info())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Check for missing values\nprint(\"\\nMissing values in the dataset:\")\nprint(df.isnull().sum())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Handle missing values (if any)\ndf.dropna(subset=['title', 'text', 'label'], inplace=True)  # Drop rows with missing text, title, or label",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Exploratory Data Analysis (EDA)\n# Word Cloud for the most frequent words in news articles\ntext = \" \".join(article for article in df['text'])\nwordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\nplt.figure(figsize=(10, 6))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.title(\"Word Cloud of Fake News Headlines\")\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Check distribution of news categories\nsns.countplot(x='label', data=df, palette='Set2')\nplt.title(\"Distribution of News Categories (Fake/Real)\")\nplt.xlabel(\"Label (0 = Fake, 1 = Real)\")\nplt.ylabel(\"Count\")\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Feature and target selection\nX = df['text']  # Features (text of the articles)\ny = df['label']  # Target (0 = Fake, 1 = Real)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}